requirements: 
  1. jdk
  2. python
  3. spark
  4. winutils

install jdk and set up environment variables
install python and set up environment variables
install spark and set up environment variables
download winutils to the preferred location ex: c:\hadoop\bin and set up environment variable for this path


run pyspark in cmd and test it
